{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**[Machine Learning Explainability Home Page](https://www.kaggle.com/learn/machine-learning-explainability)**\n\n---\n\n*This exercise involves you writing code, and we check it automatically to tell you if it's right. We're having a temporary problem with out checking infrastructure, causing a bar that says `None` in some cases when you have the right answer. We're sorry. We're fixing it. In the meantime, if you see a bar saying `None` that means you've done something good.*"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Intro\n\nYou will think about and calculate permutation importance with a sample of data from the [Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction) competition.\n\nWe won't focus on data exploration or model building for now. You can just run the cell below to \n- Load the data\n- Divide the data into training and validation\n- Build a model that predicts taxi fares\n- Print a few rows for you to review"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Loading data, dividing, modeling and EDA below\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv('../input/new-york-city-taxi-fare-prediction/train.csv', nrows=50000)\n\n# Remove data with extreme outlier coordinates or negative fares\ndata = data.query('pickup_latitude > 40.7 and pickup_latitude < 40.8 and ' +\n                  'dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and ' +\n                  'pickup_longitude > -74 and pickup_longitude < -73.9 and ' +\n                  'dropoff_longitude > -74 and dropoff_longitude < -73.9 and ' +\n                  'fare_amount > 0'\n                  )\n\ny = data.fare_amount\n\nbase_features = ['pickup_longitude',\n                 'pickup_latitude',\n                 'dropoff_longitude',\n                 'dropoff_latitude',\n                 'passenger_count']\n\nX = data[base_features]\n\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nfirst_model = RandomForestRegressor(n_estimators=50, random_state=1).fit(train_X, train_y)\n\n# Environment Set-Up for feedback system.\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.ml_explainability.ex2 import *\nprint(\"Setup Complete\")\n\n# show data\nprint(\"Data sample:\")\ndata.head()",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Setup Complete\nData sample:\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "                             key  fare_amount          pickup_datetime  \\\n2   2011-08-18 00:35:00.00000049          5.7  2011-08-18 00:35:00 UTC   \n3    2012-04-21 04:30:42.0000001          7.7  2012-04-21 04:30:42 UTC   \n4  2010-03-09 07:51:00.000000135          5.3  2010-03-09 07:51:00 UTC   \n6    2012-11-20 20:35:00.0000001          7.5  2012-11-20 20:35:00 UTC   \n7   2012-01-04 17:22:00.00000081         16.5  2012-01-04 17:22:00 UTC   \n\n   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n2        -73.982738        40.761270         -73.991242         40.750562   \n3        -73.987130        40.733143         -73.991567         40.758092   \n4        -73.968095        40.768008         -73.956655         40.783762   \n6        -73.980002        40.751662         -73.973802         40.764842   \n7        -73.951300        40.774138         -73.990095         40.751048   \n\n   passenger_count  \n2                2  \n3                1  \n4                1  \n6                1  \n7                1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>fare_amount</th>\n      <th>pickup_datetime</th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n      <th>passenger_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>2</td>\n      <td>2011-08-18 00:35:00.00000049</td>\n      <td>5.7</td>\n      <td>2011-08-18 00:35:00 UTC</td>\n      <td>-73.982738</td>\n      <td>40.761270</td>\n      <td>-73.991242</td>\n      <td>40.750562</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2012-04-21 04:30:42.0000001</td>\n      <td>7.7</td>\n      <td>2012-04-21 04:30:42 UTC</td>\n      <td>-73.987130</td>\n      <td>40.733143</td>\n      <td>-73.991567</td>\n      <td>40.758092</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2010-03-09 07:51:00.000000135</td>\n      <td>5.3</td>\n      <td>2010-03-09 07:51:00 UTC</td>\n      <td>-73.968095</td>\n      <td>40.768008</td>\n      <td>-73.956655</td>\n      <td>40.783762</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2012-11-20 20:35:00.0000001</td>\n      <td>7.5</td>\n      <td>2012-11-20 20:35:00 UTC</td>\n      <td>-73.980002</td>\n      <td>40.751662</td>\n      <td>-73.973802</td>\n      <td>40.764842</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2012-01-04 17:22:00.00000081</td>\n      <td>16.5</td>\n      <td>2012-01-04 17:22:00 UTC</td>\n      <td>-73.951300</td>\n      <td>40.774138</td>\n      <td>-73.990095</td>\n      <td>40.751048</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The following two cells may also be useful to understand the values in the training data:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_X.describe()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "       pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\ncount      23466.000000     23466.000000       23466.000000      23466.000000   \nmean         -73.976827        40.756931         -73.975359         40.757434   \nstd            0.014625         0.018206           0.015930          0.018659   \nmin          -73.999999        40.700013         -73.999999         40.700020   \n25%          -73.987964        40.744901         -73.987143         40.745756   \n50%          -73.979629        40.758076         -73.978588         40.758542   \n75%          -73.967797        40.769602         -73.966459         40.770406   \nmax          -73.900062        40.799952         -73.900062         40.799999   \n\n       passenger_count  \ncount     23466.000000  \nmean          1.662320  \nstd           1.290729  \nmin           0.000000  \n25%           1.000000  \n50%           1.000000  \n75%           2.000000  \nmax           6.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pickup_longitude</th>\n      <th>pickup_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_latitude</th>\n      <th>passenger_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>count</td>\n      <td>23466.000000</td>\n      <td>23466.000000</td>\n      <td>23466.000000</td>\n      <td>23466.000000</td>\n      <td>23466.000000</td>\n    </tr>\n    <tr>\n      <td>mean</td>\n      <td>-73.976827</td>\n      <td>40.756931</td>\n      <td>-73.975359</td>\n      <td>40.757434</td>\n      <td>1.662320</td>\n    </tr>\n    <tr>\n      <td>std</td>\n      <td>0.014625</td>\n      <td>0.018206</td>\n      <td>0.015930</td>\n      <td>0.018659</td>\n      <td>1.290729</td>\n    </tr>\n    <tr>\n      <td>min</td>\n      <td>-73.999999</td>\n      <td>40.700013</td>\n      <td>-73.999999</td>\n      <td>40.700020</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>25%</td>\n      <td>-73.987964</td>\n      <td>40.744901</td>\n      <td>-73.987143</td>\n      <td>40.745756</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>50%</td>\n      <td>-73.979629</td>\n      <td>40.758076</td>\n      <td>-73.978588</td>\n      <td>40.758542</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>75%</td>\n      <td>-73.967797</td>\n      <td>40.769602</td>\n      <td>-73.966459</td>\n      <td>40.770406</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <td>max</td>\n      <td>-73.900062</td>\n      <td>40.799952</td>\n      <td>-73.900062</td>\n      <td>40.799999</td>\n      <td>6.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_y.describe()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "count    23466.000000\nmean         8.472539\nstd          4.609747\nmin          0.010000\n25%          5.500000\n50%          7.500000\n75%         10.100000\nmax        165.000000\nName: fare_amount, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Question 1\n\nThe first model uses the following features\n- pickup_longitude\n- pickup_latitude\n- dropoff_longitude\n- dropoff_latitude\n- passenger_count\n\nBefore running any code... which variables seem potentially useful for predicting taxi fares? Do you think permutation importance will necessarily identify these features as important?\n\nOnce you've thought about it, run `q_1.solution()` below to see how you might think about this before running the code."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "q_1.solution()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 131, \"questionId\": \"1_WhichFeaturesAreUseful\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Solution: It would be helpful to know whether New York City taxis\n    vary prices based on how many passengers they have. Most places do not\n    change fares based on numbers of passengers.\n    If you assume New York City is the same, then only the top 4 features listed should matter. At first glance, it seems all of those should matter equally.\n    ",
            "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> It would be helpful to know whether New York City taxis\n    vary prices based on how many passengers they have. Most places do not\n    change fares based on numbers of passengers.\n    If you assume New York City is the same, then only the top 4 features listed should matter. At first glance, it seems all of those should matter equally.\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Question 2\n\nCreate a `PermutationImportance` object called `perm` to show the importances from `first_model`.  Fit it with the appropriate data and show the weights.\n\nFor your convenience, the code from the tutorial has been copied into a comment in this code cell."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import eli5\nfrom eli5.sklearn import PermutationImportance\n\n# Make a small change to the code below to use in this problem. \nperm = PermutationImportance(first_model, random_state=1).fit(val_X, val_y)\n\nq_2.check()\n\n# uncomment the following line to visualize your results\neli5.show_weights(perm, feature_names = val_X.columns.tolist())",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n  warnings.warn(msg, category=DeprecationWarning)\nUsing TensorFlow backend.\n",
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 131, \"questionId\": \"2_FirstPermImportance\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Nice job!: Note that these scores can vary slightly from one run to the next.\n                      But the big picture findings will stay the same each time.\n                      ",
            "text/markdown": "<span style=\"color:#33cc33\">Nice job!:</span> Note that these scores can vary slightly from one run to the next.\n                      But the big picture findings will stay the same each time.\n                      "
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n    table.eli5-weights tr:hover {\n        filter: brightness(85%);\n    }\n</style>\n\n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n    <thead>\n    <tr style=\"border: none;\">\n        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n    </tr>\n    </thead>\n    <tbody>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.8387\n                \n                    &plusmn; 0.0168\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                dropoff_latitude\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 80.10%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.8326\n                \n                    &plusmn; 0.0212\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                pickup_latitude\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 84.28%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.5947\n                \n                    &plusmn; 0.0432\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                pickup_longitude\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 85.44%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.5326\n                \n                    &plusmn; 0.0275\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                dropoff_longitude\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(0, 100.00%, 99.69%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                -0.0022\n                \n                    &plusmn; 0.0014\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                passenger_count\n            </td>\n        </tr>\n    \n    \n    </tbody>\n</table>\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Uncomment the lines below for a hint or to see the solution."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# q_2.hint()\n# q_2.solution()",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Question 3\nBefore seeing these results, we might have expected each of the 4 directional features to be equally important.\n\nBut, on average, the latitude features matter more than the longititude features. Can you come up with any hypotheses for this?\n\nAfter you've thought about it, check here for some possible explanations:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "q_3.solution()",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 131, \"questionId\": \"3_WhyLatitude\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Solution: \n    1. Travel might tend to have greater latitude distances than longitude distances. If the longitudes values were generally closer together, shuffling them wouldn't matter as much.\n    2. Different parts of the city might have different pricing rules (e.g. price per mile), and pricing rules could vary more by latitude than longitude.\n    3. Tolls might be greater on roads going North<->South (changing latitude) than on roads going East <-> West (changing longitude).  Thus latitude would have a larger effect on the prediction because it captures the amount of the tolls.\n    ",
            "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> \n    1. Travel might tend to have greater latitude distances than longitude distances. If the longitudes values were generally closer together, shuffling them wouldn't matter as much.\n    2. Different parts of the city might have different pricing rules (e.g. price per mile), and pricing rules could vary more by latitude than longitude.\n    3. Tolls might be greater on roads going North<->South (changing latitude) than on roads going East <-> West (changing longitude).  Thus latitude would have a larger effect on the prediction because it captures the amount of the tolls.\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Question 4\n\nWithout detailed knowledge of New York City, it's difficult to rule out most hypotheses about why latitude features matter more than longitude.\n\nA good next step is to disentangle the effect of being in certain parts of the city from the effect of total distance traveled.  \n\nThe code below creates new features for longitudinal and latitudinal distance. It then builds a model that adds these new features to those you already had.\n\nFill in two lines of code to calculate and show the importance weights with this new set of features. As usual, you can uncomment lines below to check your code, see a hint or get the solution."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create new features\ndata['abs_lon_change'] = abs(data.dropoff_longitude - data.pickup_longitude)\ndata['abs_lat_change'] = abs(data.dropoff_latitude - data.pickup_latitude)\n\nfeatures_2  = ['pickup_longitude',\n               'pickup_latitude',\n               'dropoff_longitude',\n               'dropoff_latitude',\n               'abs_lat_change',\n               'abs_lon_change']\n\nX = data[features_2]\nnew_train_X, new_val_X, new_train_y, new_val_y = train_test_split(X, y, random_state=1)\nsecond_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(new_train_X, new_train_y)\n\n# Create a PermutationImportance object on second_model and fit it to new_val_X and new_val_y\n# Use a random_state of 1 for reproducible results that match the expected solution.\nperm2 = PermutationImportance(second_model, random_state=1).fit(new_val_X, new_val_y)\n\n# show the weights for the permutation importance you just calculated\neli5.show_weights(perm2, feature_names = new_val_X.columns.tolist())\n\nq_4.check()",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 131, \"questionId\": \"4_ImportanceWithAbsFeatures\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Correct",
            "text/markdown": "<span style=\"color:#33cc33\">Correct</span>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# show the weights for the permutation importance you just calculated\neli5.show_weights(perm2, feature_names = new_val_X.columns.tolist())",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <style>\n    table.eli5-weights tr:hover {\n        filter: brightness(85%);\n    }\n</style>\n\n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n    <thead>\n    <tr style=\"border: none;\">\n        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n    </tr>\n    </thead>\n    <tbody>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.5786\n                \n                    &plusmn; 0.0294\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                abs_lat_change\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 83.31%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.4469\n                \n                    &plusmn; 0.0509\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                abs_lon_change\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 94.74%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0860\n                \n                    &plusmn; 0.0334\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                pickup_latitude\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 95.28%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0735\n                \n                    &plusmn; 0.0114\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                dropoff_latitude\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 95.28%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0735\n                \n                    &plusmn; 0.0101\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                dropoff_longitude\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 95.86%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0609\n                \n                    &plusmn; 0.0067\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                pickup_longitude\n            </td>\n        </tr>\n    \n    \n    </tbody>\n</table>\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "How would you interpret these importance scores? Distance traveled seems far more important than any location effects. \n\nBut the location still affects model predictions, and dropoff location now matters slightly more than pickup location. Do you have any hypotheses for why this might be? The techniques in the next lessons will help you` dive into this more."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# q_4.solution()",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Question 5\n\nA colleague observes that the values for `abs_lon_change` and `abs_lat_change` are pretty small (all values are between -0.1 and 0.1), whereas other variables have larger values.  Do you think this could explain why those coordinates had larger permutation importance values in this case?  \n\nConsider an alternative where you created and used a feature that was 100X as large for these features, and used that larger feature for training and importance calculations. Would this change the outputted permutaiton importance values?\n\nWhy or why not?\n\nAfter you have thought about your answer, either try this experiment or look up the answer in the cell below"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "q_5.solution()",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 131, \"questionId\": \"5_ScaleUpFeatureMagnitude\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Solution: \n    The scale of features does not affect permutation importance per se. The only reason that rescaling a feature would affect PI is indirectly, if rescaling helped or hurt the ability of the particular learning method we're using to make use of that feature.\n    That won't happen with tree based models, like the Random Forest used here.\n    If you are familiar with Ridge Regression, you might be able to think of how that would be affected.\n    That said, the absolute change features are have high importance because they capture total distance traveled, which is the primary determinant of taxi fares...It is not an artifact of the feature magnitude.\n    ",
            "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> \n    The scale of features does not affect permutation importance per se. The only reason that rescaling a feature would affect PI is indirectly, if rescaling helped or hurt the ability of the particular learning method we're using to make use of that feature.\n    That won't happen with tree based models, like the Random Forest used here.\n    If you are familiar with Ridge Regression, you might be able to think of how that would be affected.\n    That said, the absolute change features are have high importance because they capture total distance traveled, which is the primary determinant of taxi fares...It is not an artifact of the feature magnitude.\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Question 6\n\nYou've seen that the feature importance for latitudinal distance is greater than the importance of longitudinal distance. From this, can we conclude whether travelling a fixed latitudinal distance tends to be more expensive than traveling the same longitudinal distance?\n\nWhy or why not? Check your answer below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "q_6.solution()",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 131, \"questionId\": \"6_FromPermImportanceToMarginalEffect\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Solution: \n    We cannot tell from the permutation importance results whether traveling a fixed latitudinal distance is more or less expensive than traveling the same longitudinal distance.\n    Possible reasons latitude feature are more important than longitude features\n    1. latitudinal distances in the dataset tend to be larger\n    2. it is more expensive to travel a fixed latitudinal distance\n    3. Both of the above\n    If abs_lon_change values were very small, longitues could be less important to the model even if the cost per mile of travel in that direction were high.\n    ",
            "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> \n    We cannot tell from the permutation importance results whether traveling a fixed latitudinal distance is more or less expensive than traveling the same longitudinal distance.\n    Possible reasons latitude feature are more important than longitude features\n    1. latitudinal distances in the dataset tend to be larger\n    2. it is more expensive to travel a fixed latitudinal distance\n    3. Both of the above\n    If abs_lon_change values were very small, longitues could be less important to the model even if the cost per mile of travel in that direction were high.\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Keep Going\n\nPermutation importance is useful useful for debugging, understanding your model, and communicating a high-level overview from your model.  \n\nNext, learn about **[partial dependence plots](https://www.kaggle.com/dansbecker/partial-plots)** to see **how** each feature affects predictions.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "---\n**[Machine Learning Explainability Home Page](https://www.kaggle.com/learn/machine-learning-explainability)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}