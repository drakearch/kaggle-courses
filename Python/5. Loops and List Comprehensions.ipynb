{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**[Python Micro-Course Home Page](https://www.kaggle.com/learn/python)**\n\n---\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "These exercises accompany the tutorial on [loops and list comprehensions](https://www.kaggle.com/colinmorris/loops-and-list-comprehensions).\n\nAs always, run the setup code below before working on the questions (and if you leave this notebook and come back later, remember to run the setup code again)."
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "from learntools.core import binder; binder.bind(globals())\nfrom learntools.python.ex5 import *\nprint('Setup complete.')",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Setup complete.\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Exercises"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 1.\n\nHave you ever felt debugging involved a bit of luck? The following program has a bug. Try to identify the bug and fix it."
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "def has_lucky_number(nums):\n    \"\"\"Return whether the given list of numbers is lucky. A lucky list contains\n    at least one number divisible by 7.\n    \"\"\"\n    for num in nums:\n        if num % 7 == 0:\n            return True\n        else:\n            return False",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Try to identify the bug and fix it in the cell below:"
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "def has_lucky_number(nums):\n    \"\"\"Return whether the given list of numbers is lucky. A lucky list contains\n    at least one number divisible by 7.\n    \"\"\"\n    for num in nums:\n        if num % 7 == 0:\n            return True\n    return False\n\nq1.check()",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.Javascript object>",
                        "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 110, \"questionId\": \"1_EarlyExitDebugging\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "Correct: \n\nRemember that `return` causes a function to exit immediately. So our original implementation always ran for just one iteration. We can only return `False` if we've looked at every element of the list (and confirmed that none of them are lucky). Though we can return early if the answer is `True`:\n\n```python\ndef has_lucky_number(nums):\n    for num in nums:\n        if num % 7 == 0:\n            return True\n    # We've exhausted the list without finding a lucky number\n    return False\n```\n\nHere's a one-line version using a list comprehension with Python's `any` function (you can read about what it does by calling `help(any)`):\n\n```python\ndef has_lucky_number(nums):\n    return any([num % 7 == 0 for num in nums])\n```",
                        "text/markdown": "<span style=\"color:#33cc33\">Correct:</span> \n\nRemember that `return` causes a function to exit immediately. So our original implementation always ran for just one iteration. We can only return `False` if we've looked at every element of the list (and confirmed that none of them are lucky). Though we can return early if the answer is `True`:\n\n```python\ndef has_lucky_number(nums):\n    for num in nums:\n        if num % 7 == 0:\n            return True\n    # We've exhausted the list without finding a lucky number\n    return False\n```\n\nHere's a one-line version using a list comprehension with Python's `any` function (you can read about what it does by calling `help(any)`):\n\n```python\ndef has_lucky_number(nums):\n    return any([num % 7 == 0 for num in nums])\n```\n"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "q1.hint()\nq1.solution()",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.Javascript object>",
                        "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"learnTutorialId\": 110, \"questionId\": \"1_EarlyExitDebugging\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "Hint: How many times does the body of the loop run for a list of length n? (If you're not sure, try adding a `print()` call on the line before the `if`.)",
                        "text/markdown": "<span style=\"color:#3366cc\">Hint:</span> How many times does the body of the loop run for a list of length n? (If you're not sure, try adding a `print()` call on the line before the `if`.)"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.Javascript object>",
                        "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"learnTutorialId\": 110, \"questionId\": \"1_EarlyExitDebugging\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "Solution: Remember that `return` causes a function to exit immediately. So our original implementation always ran for just one iteration. We can only return `False` if we've looked at every element of the list (and confirmed that none of them are lucky). Though we can return early if the answer is `True`:\n\n```python\ndef has_lucky_number(nums):\n    for num in nums:\n        if num % 7 == 0:\n            return True\n    # We've exhausted the list without finding a lucky number\n    return False\n```\n\nHere's a one-line version using a list comprehension with Python's `any` function (you can read about what it does by calling `help(any)`):\n\n```python\ndef has_lucky_number(nums):\n    return any([num % 7 == 0 for num in nums])\n```",
                        "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> Remember that `return` causes a function to exit immediately. So our original implementation always ran for just one iteration. We can only return `False` if we've looked at every element of the list (and confirmed that none of them are lucky). Though we can return early if the answer is `True`:\n\n```python\ndef has_lucky_number(nums):\n    for num in nums:\n        if num % 7 == 0:\n            return True\n    # We've exhausted the list without finding a lucky number\n    return False\n```\n\nHere's a one-line version using a list comprehension with Python's `any` function (you can read about what it does by calling `help(any)`):\n\n```python\ndef has_lucky_number(nums):\n    return any([num % 7 == 0 for num in nums])\n```\n"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 2.\n\n### a.\nLook at the Python expression below. What do you think we'll get when we run it? When you've made your prediction, uncomment the code and run the cell to see if you were right."
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "#[1, 2, 3, 4] > 2",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### b\nR and Python have some libraries (like numpy and pandas) compare each element of the list to 2 (i.e. do an 'element-wise' comparison) and give us a list of booleans like `[False, False, True, True]`. \n\nImplement a function that reproduces this behaviour, returning a list of booleans corresponding to whether the corresponding element is greater than n.\n"
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "def elementwise_greater_than(L, thresh):\n    \"\"\"Return a list with the same length as L, where the value at index i is \n    True if L[i] is greater than thresh, and False otherwise.\n    \n    >>> elementwise_greater_than([1, 2, 3, 4], 2)\n    [False, False, True, True]\n    \"\"\"\n    return [num > thresh for num in L]\n\nq2.check()",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.Javascript object>",
                        "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 110, \"questionId\": \"2_ElementWiseComparison\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "Correct: \n\nHere's one solution:\n```python\ndef elementwise_greater_than(L, thresh):\n    res = []\n    for ele in L:\n        res.append(ele > thresh)\n    return res\n```\n\nAnd here's the list comprehension version:\n```python\ndef elementwise_greater_than(L, thresh):\n    return [ele > thresh for ele in L]\n```",
                        "text/markdown": "<span style=\"color:#33cc33\">Correct:</span> \n\nHere's one solution:\n```python\ndef elementwise_greater_than(L, thresh):\n    res = []\n    for ele in L:\n        res.append(ele > thresh)\n    return res\n```\n\nAnd here's the list comprehension version:\n```python\ndef elementwise_greater_than(L, thresh):\n    return [ele > thresh for ele in L]\n```\n"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "q2.solution()",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.Javascript object>",
                        "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"learnTutorialId\": 110, \"questionId\": \"2_ElementWiseComparison\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "Solution: Here's one solution:\n```python\ndef elementwise_greater_than(L, thresh):\n    res = []\n    for ele in L:\n        res.append(ele > thresh)\n    return res\n```\n\nAnd here's the list comprehension version:\n```python\ndef elementwise_greater_than(L, thresh):\n    return [ele > thresh for ele in L]\n```",
                        "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> Here's one solution:\n```python\ndef elementwise_greater_than(L, thresh):\n    res = []\n    for ele in L:\n        res.append(ele > thresh)\n    return res\n```\n\nAnd here's the list comprehension version:\n```python\ndef elementwise_greater_than(L, thresh):\n    return [ele > thresh for ele in L]\n```\n"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 3.\n\nComplete the body of the function below according to its docstring"
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "def menu_is_boring(meals):\n    \"\"\"Given a list of meals served over some period of time, return True if the\n    same meal has ever been served two days in a row, and False otherwise.\n    \"\"\"\n    for i in range(len(meals)-1):\n        if meals[i] == meals[i+1]:\n            return True\n    return False\n\nq3.check()",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.Javascript object>",
                        "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 110, \"questionId\": \"3_BoringMenu\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "Correct: \n\n\n\n```python\ndef menu_is_boring(meals):\n    # Iterate over all indices of the list, except the last one\n    for i in range(len(meals)-1):\n        if meals[i] == meals[i+1]:\n            return True\n    return False\n```\n\nThe key to our solution is the call to `range`. `range(len(meals))` would give us all the indices of `meals`. If we had used that range, the last iteration of the loop would be comparing the last element to the element after it, which is... `IndexError`! `range(len(meals)-1)` gives us all the indices except the index of the last element.\n\nBut don't we need to check if `meals` is empty? Turns out that `range(0) == range(-1)` - they're both empty. So if `meals` has length 0 or 1, we just won't do any iterations of our for loop.",
                        "text/markdown": "<span style=\"color:#33cc33\">Correct:</span> \n\n\n\n```python\ndef menu_is_boring(meals):\n    # Iterate over all indices of the list, except the last one\n    for i in range(len(meals)-1):\n        if meals[i] == meals[i+1]:\n            return True\n    return False\n```\n\nThe key to our solution is the call to `range`. `range(len(meals))` would give us all the indices of `meals`. If we had used that range, the last iteration of the loop would be comparing the last element to the element after it, which is... `IndexError`! `range(len(meals)-1)` gives us all the indices except the index of the last element.\n\nBut don't we need to check if `meals` is empty? Turns out that `range(0) == range(-1)` - they're both empty. So if `meals` has length 0 or 1, we just won't do any iterations of our for loop.\n"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "q3.hint()\nq3.solution()",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.Javascript object>",
                        "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"learnTutorialId\": 110, \"questionId\": \"3_BoringMenu\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "Hint: This is a case where it may be preferable to iterate over the *indices* of the list (using a call to `range()`) rather than iterating over the elements of the list itself. When indexing into the list, be mindful that you're not \"falling off the end\" (i.e. using an index that doesn't exist).",
                        "text/markdown": "<span style=\"color:#3366cc\">Hint:</span> This is a case where it may be preferable to iterate over the *indices* of the list (using a call to `range()`) rather than iterating over the elements of the list itself. When indexing into the list, be mindful that you're not \"falling off the end\" (i.e. using an index that doesn't exist)."
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.Javascript object>",
                        "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"learnTutorialId\": 110, \"questionId\": \"3_BoringMenu\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "Solution: \n\n```python\ndef menu_is_boring(meals):\n    # Iterate over all indices of the list, except the last one\n    for i in range(len(meals)-1):\n        if meals[i] == meals[i+1]:\n            return True\n    return False\n```\n\nThe key to our solution is the call to `range`. `range(len(meals))` would give us all the indices of `meals`. If we had used that range, the last iteration of the loop would be comparing the last element to the element after it, which is... `IndexError`! `range(len(meals)-1)` gives us all the indices except the index of the last element.\n\nBut don't we need to check if `meals` is empty? Turns out that `range(0) == range(-1)` - they're both empty. So if `meals` has length 0 or 1, we just won't do any iterations of our for loop.",
                        "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> \n\n```python\ndef menu_is_boring(meals):\n    # Iterate over all indices of the list, except the last one\n    for i in range(len(meals)-1):\n        if meals[i] == meals[i+1]:\n            return True\n    return False\n```\n\nThe key to our solution is the call to `range`. `range(len(meals))` would give us all the indices of `meals`. If we had used that range, the last iteration of the loop would be comparing the last element to the element after it, which is... `IndexError`! `range(len(meals)-1)` gives us all the indices except the index of the last element.\n\nBut don't we need to check if `meals` is empty? Turns out that `range(0) == range(-1)` - they're both empty. So if `meals` has length 0 or 1, we just won't do any iterations of our for loop.\n"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 4. <span title=\"A bit spicy\" style=\"color: darkgreen \">üå∂Ô∏è</span>\n\nNext to the Blackjack table, the Python Challenge Casino has a slot machine. You can get a result from the slot machine by calling `play_slot_machine()`. The number it returns is your winnings in dollars. Usually it returns 0.  But sometimes you'll get lucky and get a big payday. Try running it below:"
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "play_slot_machine()",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 10,
                    "data": {
                        "text/plain": "0"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "By the way, did we mention that each play costs $1? Don't worry, we'll send you the bill later.\n\nOn average, how much money can you expect to gain (or lose) every time you play the machine?  The casino keeps it a secret, but you can estimate the average value of each pull using a technique called the **Monte Carlo method**. To estimate the average outcome, we simulate the scenario many times, and return the average result.\n\nComplete the following function to calculate the average value per play of the slot machine."
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "def estimate_average_slot_payout(n_runs):\n    \"\"\"Run the slot machine n_runs times and return the average net profit per run.\n    Example calls (note that return value is nondeterministic!):\n    >>> estimate_average_slot_payout(1)\n    -1\n    >>> estimate_average_slot_payout(1)\n    0.5\n    \"\"\"\n    pool = 0\n    for i in range(n_runs):\n        pool += play_slot_machine()\n    return (pool - n_runs) / n_runs\n\nestimate_average_slot_payout(10000000)",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 11,
                    "data": {
                        "text/plain": "0.02565745"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "When you think you know the expected value per spin, uncomment the line below to see how close you were."
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "q4.solution()",
            "execution_count": 12,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.Javascript object>",
                        "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 110, \"questionId\": \"4_ExpectedSlotsPayout\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "Solution: The exact expected value of one pull of the slot machine is 0.025 - i.e. a little more than 2 cents. See? Not every game in the Python Challenge Casino is rigged against the player!\n\nBecause of the high variance of the outcome (there are some very rare high payout results that significantly affect the average) you might need to run your function with a very high value of `n_runs` to get a stable answer close to the true expectation.\n\nIf your answer is way higher than 0.025, then maybe you forgot to account for the $1 cost per play?",
                        "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> The exact expected value of one pull of the slot machine is 0.025 - i.e. a little more than 2 cents. See? Not every game in the Python Challenge Casino is rigged against the player!\n\nBecause of the high variance of the outcome (there are some very rare high payout results that significantly affect the average) you might need to run your function with a very high value of `n_runs` to get a stable answer close to the true expectation.\n\nIf your answer is way higher than 0.025, then maybe you forgot to account for the $1 cost per play?"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Keep Going\n\nYou are ready for **[strings and dictionaries](https://www.kaggle.com/colinmorris/strings-and-dictionaries).**\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "---\n**[Python Micro-Course Home Page](https://www.kaggle.com/learn/python)**\n\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.5"
        },
        "learntools_metadata": {
            "lesson_index": 4,
            "type": "exercise"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}